{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Trading Strategies - Tutorial Introdutorio\n",
    "\n",
    "Este notebook demonstra o pipeline completo do framework:\n",
    "\n",
    "1. Gerar dados sinteticos de mercado\n",
    "2. Engenharia de features (indicadores tecnicos)\n",
    "3. Treinar modelos de ML\n",
    "4. Backtesting da estrategia\n",
    "5. Analise de performance\n",
    "\n",
    "**Aviso:** Projeto educacional. Nao constitui aconselhamento financeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gerar Dados Sinteticos\n",
    "\n",
    "Usamos dados sinteticos para evitar dependencia de internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_stock_data(n_days=1000, initial_price=100, volatility=0.02, trend=0.0001):\n",
    "    \"\"\"Generate synthetic OHLCV data.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    returns = np.random.normal(trend, volatility, n_days)\n",
    "    prices = initial_price * np.exp(np.cumsum(returns))\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'date': pd.date_range(start='2020-01-01', periods=n_days, freq='D'),\n",
    "        'open': prices * (1 + np.random.uniform(-0.005, 0.005, n_days)),\n",
    "        'high': prices * (1 + np.random.uniform(0, 0.01, n_days)),\n",
    "        'low': prices * (1 - np.random.uniform(0, 0.01, n_days)),\n",
    "        'close': prices,\n",
    "        'volume': np.random.randint(1000000, 5000000, n_days),\n",
    "    })\n",
    "    data['high'] = data[['open', 'high', 'close']].max(axis=1)\n",
    "    data['low'] = data[['open', 'low', 'close']].min(axis=1)\n",
    "    return data\n",
    "\n",
    "data = generate_synthetic_stock_data(n_days=1000)\n",
    "print(f\"Generated {len(data)} days of data\")\n",
    "print(f\"Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(data['date'], data['close'], linewidth=1)\n",
    "plt.title('Synthetic Stock Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Engenharia de Features\n",
    "\n",
    "Adicionar indicadores tecnicos ao dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.technical_indicators import TechnicalIndicators\n",
    "\n",
    "indicators = TechnicalIndicators()\n",
    "data_with_features = indicators.add_all_features(data.copy())\n",
    "\n",
    "print(f\"Features added: {data_with_features.shape[1] - data.shape[1]} indicators\")\n",
    "print(f\"Total columns: {data_with_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Price with Moving Averages\n",
    "axes[0].plot(data_with_features['date'], data_with_features['close'], label='Close', linewidth=1.5)\n",
    "axes[0].plot(data_with_features['date'], data_with_features['sma_20'], label='SMA 20', alpha=0.7)\n",
    "axes[0].plot(data_with_features['date'], data_with_features['sma_50'], label='SMA 50', alpha=0.7)\n",
    "axes[0].set_title('Price with Moving Averages')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RSI\n",
    "axes[1].plot(data_with_features['date'], data_with_features['rsi_14'], color='purple', linewidth=1.5)\n",
    "axes[1].axhline(y=70, color='r', linestyle='--', alpha=0.5, label='Overbought')\n",
    "axes[1].axhline(y=30, color='g', linestyle='--', alpha=0.5, label='Oversold')\n",
    "axes[1].set_title('RSI (14)')\n",
    "axes[1].set_ylim(0, 100)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# MACD\n",
    "axes[2].plot(data_with_features['date'], data_with_features['macd'], label='MACD', linewidth=1.5)\n",
    "axes[2].plot(data_with_features['date'], data_with_features['macd_signal'], label='Signal', linewidth=1.5)\n",
    "axes[2].bar(data_with_features['date'], data_with_features['macd_hist'], label='Histogram', alpha=0.3)\n",
    "axes[2].set_title('MACD')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criar Variavel Alvo e Dividir Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "\n",
    "loader = DataLoader()\n",
    "\n",
    "# 3-class target: 0=down, 1=neutral, 2=up\n",
    "data_with_features['target'] = loader.create_target_variable(\n",
    "    data_with_features, horizon=5, threshold=0.01, binary=False\n",
    ")\n",
    "data_with_features = data_with_features.dropna()\n",
    "\n",
    "print(f\"Dataset: {len(data_with_features)} rows\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(data_with_features['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = loader.prepare_training_data(\n",
    "    data_with_features, target_col='target', test_size=0.2, validation_size=0.1\n",
    ")\n",
    "\n",
    "print(f\"Training set:   {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set:       {X_test.shape[0]} samples\")\n",
    "print(f\"Features:       {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinar Modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ml_models import TradingModel, EnsembleModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Train models\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = TradingModel(model_type='random_forest', n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = TradingModel(model_type='xgboost', n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "lgb_model = TradingModel(model_type='lightgbm', n_estimators=100, random_state=42)\n",
    "lgb_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"All models trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "models = {'Random Forest': rf_model, 'XGBoost': xgb_model, 'LightGBM': lgb_model}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_val)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_val, preds),\n",
    "        'Precision': precision_score(y_val, preds, average='weighted', zero_division=0),\n",
    "        'Recall': recall_score(y_val, preds, average='weighted', zero_division=0),\n",
    "        'F1 Score': f1_score(y_val, preds, average='weighted', zero_division=0)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Validation Performance:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble e Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble\n",
    "ensemble = EnsembleModel([rf_model, xgb_model, lgb_model])\n",
    "ensemble.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "ens_preds = ensemble.predict(X_val)\n",
    "print(f\"Ensemble Accuracy: {accuracy_score(y_val, ens_preds):.4f}\")\n",
    "print(f\"Ensemble F1:       {f1_score(y_val, ens_preds, average='weighted', zero_division=0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (from Random Forest)\n",
    "fi = rf_model.get_feature_importance(top_n=15)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(fi['feature'][::-1], fi['importance'][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Features (Random Forest)')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting.backtest_engine import BacktestEngine\n",
    "\n",
    "backtest = BacktestEngine(initial_capital=100000, commission=0.001, slippage=0.0005)\n",
    "\n",
    "# Generate signals from ensemble\n",
    "predictions = ensemble.predict_proba(X_test)\n",
    "signals = backtest.generate_signals_from_predictions(predictions, threshold=0.55)\n",
    "\n",
    "# Run backtest\n",
    "test_data = data_with_features.iloc[-len(X_test):].copy()\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "signals_series = pd.Series(signals).reset_index(drop=True)\n",
    "\n",
    "results = backtest.run_backtest(test_data, signals_series, price_col='close')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BACKTEST RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Initial Capital:      ${backtest.initial_capital:,.2f}\")\n",
    "print(f\"Final Portfolio:      ${results.equity_curve.iloc[-1]:,.2f}\")\n",
    "print(f\"Total Return:         {results.total_return:.2%}\")\n",
    "print(f\"Annualized Return:    {results.annualized_return:.2%}\")\n",
    "print(f\"Sharpe Ratio:         {results.sharpe_ratio:.2f}\")\n",
    "print(f\"Max Drawdown:         {results.max_drawdown:.2%}\")\n",
    "print(f\"Win Rate:             {results.win_rate:.2%}\")\n",
    "print(f\"Profit Factor:        {results.profit_factor:.2f}\")\n",
    "print(f\"Total Trades:         {results.total_trades}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Buy & Hold comparison\n",
    "bh_return = (test_data['close'].iloc[-1] / test_data['close'].iloc[0]) - 1\n",
    "print(f\"\\nBuy & Hold Return:    {bh_return:.2%}\")\n",
    "print(f\"Outperformance:       {(results.total_return - bh_return):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot equity curve\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(results.equity_curve)\n",
    "axes[0].set_title('Equity Curve')\n",
    "axes[0].set_ylabel('Portfolio Value ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Drawdown\n",
    "rets = results.equity_curve.pct_change()\n",
    "cumulative = (1 + rets).cumprod()\n",
    "running_max = cumulative.cummax()\n",
    "drawdown = (cumulative - running_max) / running_max\n",
    "\n",
    "axes[1].fill_between(drawdown.index, drawdown, 0, alpha=0.5, color='red')\n",
    "axes[1].set_title('Drawdown')\n",
    "axes[1].set_ylabel('Drawdown')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusao\n",
    "\n",
    "Este tutorial demonstrou o pipeline completo:\n",
    "- Geracao de dados sinteticos OHLCV\n",
    "- Calculo de indicadores tecnicos\n",
    "- Treinamento de modelos (Random Forest, XGBoost, LightGBM)\n",
    "- Ensemble com majority voting\n",
    "- Backtesting com custos de transacao\n",
    "\n",
    "**Aviso:** Resultados em dados sinteticos nao representam performance real.\n",
    "Para dados reais, use `DataLoader.download_stock_data()` ou o exemplo em `examples/complete_strategy.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
