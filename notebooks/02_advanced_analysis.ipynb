{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise Avancada de Features e Modelos\n",
    "\n",
    "Este notebook demonstra:\n",
    "- Analise de correlacao entre features\n",
    "- Comparacao detalhada de modelos\n",
    "- Analise de confianca nas predicoes\n",
    "\n",
    "Pre-requisito: ter completado o tutorial basico (notebook 01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data_loader import DataLoader\n",
    "from features.technical_indicators import TechnicalIndicators\n",
    "from models.ml_models import TradingModel\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_stock_data(n_days=1000, initial_price=100, volatility=0.02, trend=0.0001):\n",
    "    np.random.seed(42)\n",
    "    returns = np.random.normal(trend, volatility, n_days)\n",
    "    prices = initial_price * np.exp(np.cumsum(returns))\n",
    "    data = pd.DataFrame({\n",
    "        'date': pd.date_range(start='2020-01-01', periods=n_days, freq='D'),\n",
    "        'open': prices * (1 + np.random.uniform(-0.005, 0.005, n_days)),\n",
    "        'high': prices * (1 + np.random.uniform(0, 0.01, n_days)),\n",
    "        'low': prices * (1 - np.random.uniform(0, 0.01, n_days)),\n",
    "        'close': prices,\n",
    "        'volume': np.random.randint(1000000, 5000000, n_days),\n",
    "    })\n",
    "    data['high'] = data[['open', 'high', 'close']].max(axis=1)\n",
    "    data['low'] = data[['open', 'low', 'close']].min(axis=1)\n",
    "    return data\n",
    "\n",
    "loader = DataLoader()\n",
    "data = generate_synthetic_stock_data(n_days=1000)\n",
    "\n",
    "indicators = TechnicalIndicators()\n",
    "data_with_features = indicators.add_all_features(data.copy())\n",
    "data_with_features['target'] = loader.create_target_variable(\n",
    "    data_with_features, horizon=5, threshold=0.01, binary=False\n",
    ")\n",
    "data_with_features = data_with_features.dropna()\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = loader.prepare_training_data(\n",
    "    data_with_features, target_col='target'\n",
    ")\n",
    "\n",
    "print(f\"Data prepared: {X_train.shape[0]} train, {X_val.shape[0]} val, {X_test.shape[0]} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analise de Correlacao entre Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "plt.imshow(correlation_matrix.values, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "plt.colorbar(shrink=0.8)\n",
    "plt.title('Feature Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "high_corr_pairs = []\n",
    "cols = correlation_matrix.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr_pairs.append((cols[i], cols[j], correlation_matrix.iloc[i, j]))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"\\nHighly correlated pairs (|r| > 0.9): {len(high_corr_pairs)}\")\n",
    "    for feat1, feat2, corr in high_corr_pairs[:10]:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No highly correlated features found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparacao de Modelos com Diferentes Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    ('XGB depth=3', 'xgboost', {'max_depth': 3, 'n_estimators': 100}),\n",
    "    ('XGB depth=6', 'xgboost', {'max_depth': 6, 'n_estimators': 100}),\n",
    "    ('XGB depth=10', 'xgboost', {'max_depth': 10, 'n_estimators': 100}),\n",
    "    ('RF n=50', 'random_forest', {'n_estimators': 50}),\n",
    "    ('RF n=200', 'random_forest', {'n_estimators': 200}),\n",
    "    ('LGB lr=0.05', 'lightgbm', {'learning_rate': 0.05, 'n_estimators': 100}),\n",
    "    ('LGB lr=0.2', 'lightgbm', {'learning_rate': 0.2, 'n_estimators': 100}),\n",
    "]\n",
    "\n",
    "comparison = []\n",
    "for name, model_type, params in configs:\n",
    "    model = TradingModel(model_type=model_type, random_state=42, **params)\n",
    "    model.fit(X_train, y_train, X_val, y_val)\n",
    "    val_preds = model.predict(X_val)\n",
    "    test_preds = model.predict(X_test)\n",
    "    comparison.append({\n",
    "        'Config': name,\n",
    "        'Val Accuracy': accuracy_score(y_val, val_preds),\n",
    "        'Test Accuracy': accuracy_score(y_test, test_preds),\n",
    "    })\n",
    "\n",
    "comp_df = pd.DataFrame(comparison)\n",
    "print(comp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(comp_df))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, comp_df['Val Accuracy'], width, label='Validation')\n",
    "ax.bar(x + width/2, comp_df['Test Accuracy'], width, label='Test')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comp_df['Config'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinar Melhor Modelo e Analisar Predicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best config (pick the one with highest val accuracy)\n",
    "best_idx = comp_df['Val Accuracy'].idxmax()\n",
    "best_name, best_type, best_params = configs[best_idx]\n",
    "print(f\"Best config: {best_name}\")\n",
    "\n",
    "best_model = TradingModel(model_type=best_type, random_state=42, **best_params)\n",
    "best_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "test_preds = best_model.predict(X_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test, test_preds):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analise de Confianca nas Predicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas = best_model.predict_proba(X_test)\n",
    "confidence = np.max(test_probas, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confidence distribution\n",
    "axes[0].hist(confidence, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=confidence.mean(), color='r', linestyle='--', label=f'Mean: {confidence.mean():.3f}')\n",
    "axes[0].set_xlabel('Confidence')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Prediction Confidence Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy by confidence level\n",
    "conf_bins = [0, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "acc_by_conf = []\n",
    "n_by_conf = []\n",
    "\n",
    "for i in range(len(conf_bins)-1):\n",
    "    mask = (confidence >= conf_bins[i]) & (confidence < conf_bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        acc_by_conf.append(accuracy_score(y_test[mask], test_preds[mask]))\n",
    "        n_by_conf.append(mask.sum())\n",
    "    else:\n",
    "        acc_by_conf.append(0)\n",
    "        n_by_conf.append(0)\n",
    "\n",
    "bin_labels = [f'{conf_bins[i]:.1f}-{conf_bins[i+1]:.1f}' for i in range(len(conf_bins)-1)]\n",
    "x = np.arange(len(bin_labels))\n",
    "\n",
    "bars = axes[1].bar(x, acc_by_conf, alpha=0.7)\n",
    "axes[1].set_xlabel('Confidence Range')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy by Confidence Level')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(bin_labels, rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, count in zip(bars, n_by_conf):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height, f'n={count}',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean Confidence: {confidence.mean():.4f}\")\n",
    "print(f\"High Confidence (>0.7): {(confidence > 0.7).sum()} samples ({(confidence > 0.7).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusao\n",
    "\n",
    "Neste notebook analisamos:\n",
    "\n",
    "1. **Correlacao entre features** - quais indicadores sao redundantes\n",
    "2. **Comparacao de hiperparametros** - impacto de profundidade, learning rate, etc.\n",
    "3. **Confianca do modelo** - como a probabilidade maxima se relaciona com acuracia\n",
    "\n",
    "Proximos passos:\n",
    "- Remover features altamente correlacionadas para reduzir overfitting\n",
    "- Usar niveis de confianca para filtrar sinais de trading\n",
    "- Experimentar com diferentes horizontes de predicao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
